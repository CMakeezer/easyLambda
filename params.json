{
  "name": "Easylambda",
  "tagline": "A fresh take on data-flow with map and reduce on modern C++ and MPI.",
  "body": "## Long story short\r\n\r\nThe project started with the need for a standard way to process data with\r\nC++. The design goals are composability, easy interface, decoupling IO,\r\ndata-format and parallel code from algorithm logic, less boilerplate code,\r\naccessible to anyone who knows C. easyLambda achieves these goals with type-safe\r\ndata-flow pipeline, map/reduce like operations, MPI parallelism; presented with\r\nan easy but powerful\r\n[ExpressionBuilder](http://martinfowler.com/bliki/ExpressionBuilder.html)\r\ninterface made possible by use of modern C++ features.\r\n\r\nCheck the [tutorials](doc/tutorial/contents.md) to begin coding with ezl.\r\n\r\n## Why easyLambda\r\n\r\nUse ezl for your data-processing tasks, to write post-processors for simulation\r\nresults, for iterative machine learning algorithms, for general list data\r\nprocessing or any data / task parallel code. Processing a flat-file with ezl is\r\nas simple and declarative as working with spreadsheet program or writing a SQL\r\nquery, but using C / C++ functions. You get an expressive way to compose\r\nthe algorithms as a data-flow of small tasks, clean separation of \r\nalgorithm logic from i/o, data-formats or parallelism, various built-in\r\nfunctions for common operations and MPI parallelism with no to little extra\r\ncode. The library presents no special structure, data-types or requirements on\r\nthe user functions. Moreover, it facilitates composition of functions with\r\ncore algorithm logic, irrespective of nearby columns using column selection. A\r\nuniform interface with just map and reduce computations simplifies programming.\r\nCheck the examples listed below to know some of the ways ezl has been used.\r\n\r\nYou can use it along with other libraries like openCV/Dlib/thrust that work\r\nwell with standard data-types.\r\n\r\nIf you are a C++ enthusiast then possibly you will find the project quite\r\ninteresting. It uses template parameters in new ways to form a good interface\r\nbased on them. It makes good use of a lot of modern C++ features including \r\nvariadics, move-semantics, tuples, type-traits. \r\n\r\nContributions and feedback of any kind are much appreciated.\r\nPlease check [contributing.md](contributing.md) for more.\r\n\r\n#### Related works: \r\nThere is no other C++ library that provides map, reduce with data-flow. ezl\r\nalso provides MPI parallelism which notwithstanding to its extensive use in\r\nhigh performance computing, lacks good library support written on top of it.\r\nIt does have various distinguishing features such as cyclic data-flows,\r\nparallelism as a property, column selection for composition, many implicit\r\nchoices implemented with traits.\r\n\r\nThere are some libraries that offer data-flow in C++ such as boost data-flow,\r\ntbb graphs, phish. Unlike functional paradigm languages and libraries, they\r\nhave bloated syntax of varying degree with explicit graphs,\r\nedges, nodes, all sort of classes, functions with unusual signatures. It \r\ndefies the motive of facilitating composition of pure functions that have\r\nnothing but algorithm logic for better reuse, modularity and parallelism\r\nwithout bloat-code, as seen in nodejs promises, scala libraries and is one of the\r\nmotivation for Monad idiom. \r\n\r\nIn ezl, the user functions have no dependency on library and require no extra\r\nconstruct. They just take multiple input parameters as usual and return the\r\nresult. Moreover, there is a lot of emphasis on column selection to use the\r\nfunctions in the data-flow that do not exactly match the inputs coming. The use\r\nof map and reduce as the only units simplifies the code and enables\r\ndata-parallelism along with task-parallelism inherent to data-flow.\r\n\r\n## Overview\r\n\r\nHere is a short example to begin with. The program calculates\r\nfrequency of each word in the data files. Words are considered same\r\nirrespective of their case (upper or lower).\r\n\r\n#### [Example wordcount](examples/wordcount.cpp)\r\n```cpp\r\n#include <string>\r\n\r\n#include <boost/mpi.hpp>\r\n\r\n#include <ezl/ezl.hpp>\r\n#include <ezl/algorithms/fromFile.hpp>\r\n#include <ezl/algorithms/reduces.hpp>\r\n\r\nint main(int argc, char* argv[]) {\r\n  using std::string;\r\n  using ezl::fromFile;\r\n  boost::mpi::environment env(argc, argv);\r\n\r\n  ezl::rise(fromFile<string>(argv[1]).rowSeparator('s').colSeparator(\"\"))\r\n    .reduce<1>(ezl::count(), 0).dump()\r\n    .run();\r\n  return 0;\r\n}\r\n```\r\nThe data-flow starts with `rise` and subsequent operations are added to the\r\npipeline. In the above example, the pipeline starts with reading data from\r\nfile(s). `fromFile` is a library function that takes column types and file(s)\r\nglob pattern as input and reads the file(s) in parallel. It has a lot of\r\nproperties for controlling data-format, parallelism, denormalization etc\r\n(shown in [demoFromFile](examples/demoFromFile.cpp)).\r\n\r\nIn reduce we pass the index of the key column to group by, the library function\r\nfor counting and initial value of the result. The wordcount example is too\r\nsimple to show much of the library features. \r\n\r\nFollowing is the data-flow for calculating pi using Monte-Carlo method.\r\n\r\n#### [Example pi (Monte-Carlo)](examples/pi.cpp)\r\n```cpp\r\nezl::rise(ezl::kick(10000)) // 10000 trials shared over all processes\r\n  .map([] { \r\n    auto x = rand01();\r\n    auto y = rand01();\r\n    return x*x + y*y; \r\n  })\r\n  .filter(ezl::lt(1.))\r\n  .reduce(ezl::count(), 0)\r\n  .map([](int inCircleCount) { \r\n    return (4.0 * inCircleCount / 10000); \r\n  }).colsTransform().dump()\r\n  .run();\r\n```\r\n\r\nThe steps in the algorithm have been expressed with the composition of small\r\noperations, some are common library functions like `count()`, `lt()` (less-than) and\r\nsome are user-defined functions specific to problem.\r\n\r\nNot only the above examples are expressive and modular, they are highly\r\nefficient in serial as well as parallel execution, with close to linear\r\nspeed-up with multiple cores or multiple nodes. The implementation aims at\r\nreducing number of copies of the data, which results in little to no overhead\r\nover a serial code written specifically to carry out the same operation.\r\n\r\nHere is another example from\r\n[cods2016](http://ikdd.acm.org/Site/CoDS2016/datachallenge.html). A stripped\r\nversion of the input data-file is given with ezl\r\n[here](data/datachallenge_cods2016/train.csv). The data contains student\r\nprofiles with scores, gender, job-salary, city etc.\r\n\r\n#### [Example cods2016](examples/cods2016.cpp)\r\n```cpp\r\nauto scores = ezl::fromFile<char, array<float, 3>>(fileName)\r\n                .cols({\"Gender\", \"English\", \"Logical\", \"Domain\"})\r\n                .colSeparator(\"\\t\");\r\n\r\nezl::rise(scores)\r\n  .filter<2>(ezl::gtAr<3>(0.F))   // filter valid domain scores > 0\r\n  .map<1>([] (char gender) {      // transforming with 0/1 for isMale\r\n    return float(gender == 'm');\r\n  }).colsTransform()\r\n  .reduceAll(ezl::corr<1>())\r\n    .dump(\"\", \"Corr. of gender with scores\\n(gender|E|L|D)\")\r\n  .run();\r\n```\r\n\r\nThe above example prints the correlation of English, logical and domain scores\r\nwith respect to gender. We can find similarity of the above code with steps in\r\na spreadsheet analysis or with SQL query. We select the columns to work with\r\nviz. gender and three scores. We filter the rows based on a column and predicate.\r\nNext, we transform a selected column in-place and then find an aggregate property\r\n(correlation) for all the rows.\r\n\r\n\r\nYou can find the above examples and many more in detail with benchmarking\r\nresults in the [examples directory](examples). Examples include:\r\n\r\n - logistic regression training and testing. [logreg.cpp](examples/logreg.cpp).\r\n - displaced atoms count and self interstitial count for post-processing\r\n   [LAMMPS](http://lammps.sandia.gov/) simulation results.\r\n   [displaced.cpp](examples/displaced.cpp),\r\n   [interstitialcount.cpp](examples/interstitialcount.cpp).\r\n - example for having a overview of data stats with example from\r\n   [cods2016](http://ikdd.acm.org/Site/CoDS2016/datachallenge.html).\r\n   [cods2016.cpp](examples/cods2016.cpp).\r\n - given a trajectory with positions at different times, finding the count of\r\n   directions of adjacent steps in the trajectory.\r\n   [trajectory.cpp](examples/trajectory.cpp).\r\n\r\nThe examples directory also has separate demonstrations for features and\r\noptions along with explanations to get started with ezl quickly.\r\n\r\n### Parallelism\r\n\r\nThe ezl makes good use of task parallelism inherent in data-flows and\r\ndata parallelism inherent in map and reduce tasks for a default optimum\r\nparallelism and providing a property based interface to override if \r\nrequired. The following figure shows the overview of parallel options for\r\nunits in a pipeline. \r\n\r\n![Parallel options](doc/prll.png)\r\n\r\nThe numbers inside the circle are process rank a unit is running on.  for e.g.\r\nfirst unit can be a fromFile running on {0, 1} process ranks, {2,3,4} can be\r\nrunning a map or reduce and so on. It can be seen that a reduce task is by\r\ndefault parallel and map tasks are by default in-process. The prll option in\r\nthe units control the behavior. The processes can be requested by number,\r\nratio of processes of parent unit, or exact rank of processes. If the requested\r\nprocesses are not available then also the program runs correctly with best\r\npossible allocation to units. [demoPrll](examples/demoPrll.cpp) has detailed\r\nexamples and options on this. A lot of other demos and examples use `prll`\r\noption with different units and options.\r\n\r\nFollowing are some benchmark results on different problems.\r\n\r\n![benchmarks](doc/benchmarks.png)\r\n\r\nThe number of trials for pi are doubled as the number of processes are doubled,\r\nkeeping the trials per process constant (weak scaling). In this case a constant\r\nline implies ideal parallelism. The logistic regression and wordcount\r\nbenchmarks show decrease in time of execution unless the time is reduced to\r\naround a minute. For more info on benchmarks check the respective examples.\r\n\r\n### Data-flow\r\n\r\nThere are no restrictions on data-flow connections except the type of columns.\r\nThe following figures demonstrates a circular data-flow and a diamond like\r\ndata-flow pipelines: \r\n\r\n![dataflow](doc/dataflow.png)\r\n\r\nEach of these tasks can be running on multiple processes, depending on the\r\navailability and options. \r\n\r\nThere can also be a data-flow running in user function of another data-flow. The\r\ndata-flows can be joined, branched and built to run later multiple times on\r\ndifferent data.\r\n\r\n[demoFlow](examples/demoFlow.cpp) shows code and details for the options\r\ndiscussed and for above two data-flow figures. Many other examples also use\r\nflow properties.\r\n\r\n## Quick Start\r\nCheck out the [tutorial](doc/tutorial/contents.md) to begin coding with ezl.\r\nFeel free to ask for any specific queries.\r\n\r\n## How to install\r\n\r\n### Requirements\r\n- c++14 compliant compiler and MPI (mpic++/mpicxx and mpirun)\r\n   - Works with gcc-5.1 or later and clang-3.5 or later.\r\n   - Tested with gcc-5.3, gcc-6.0(dev. branch), Apple LLVM version 7.0.0 (clang-700.0.72).\r\n- boost::mpi, boost::serialization tested with 5.8 and 6.0.\r\n\r\n### Installing\r\nThis is a header only library so all that is needed to start using is to place \r\nthe contents of the [include](include) directory within your source tree so that\r\nit is available to the compiler. Include [include/ezl.hpp](include/ezl.hpp) in\r\nyour program. If you use algorithms like `ezl::count` etc then also include\r\nrequired files from [include/ezl/algorithms/](include/ezl/algorithms/)\r\ndirectory.\r\n\r\n### Compiling\r\nThere are no linking requirements of ezl library but it uses boost::serialization\r\nand boost::mpi that need to be linked.\r\nHere is how you can compile a program in general:\r\n`mpic++ file.cpp -Wall -std=c++14 -O3 -I path_to_ezl_include -lboost_mpi -lboost_serialization`\r\n\r\nIf you have added the contents of include directory to your source tree or global\r\nincludes then you don't need to pass -I path_to_ezl_include flag.\r\n\r\nYou can compile unit-tests with `make unittest` and run with `./bin/unitTest`.\r\n\r\nYou can compile an example using make with `make example fname=name`, in place\r\nof name write the name of the file for e.g. wordcount without extension.\r\n\r\n### Running\r\n\r\nAfter compiling, the executable can be run with mpirun \r\n`mpirun -n 4 path_to_exe args…` or simply as `path_to_exe args…`.\r\n\r\n----\r\n\r\nA big thanks to cppcon, meetingc++ and other conferences and all pro C++\r\nspeakers, committee members and compiler implementers for modernising C++ and\r\nteaching it with so much enthusiasm. I had fun implementing this, hoping\r\nyou will have fun using it. Looking forward to learn more from the community.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}